#
# Parameters to start a simulation with a trader
# @renero
#

# Data Path. Where is the data from which l#earning how to invest?
data_path: ../data/forecast100.csv

# Wanna save the model after training?
save_model: true
models_dir: ../output/

# Specify here if you want to load a pre-trained model
load_model: false
model_file: ../output/model.json
weights_file: ../output/model.h5

# Parameters for the Q-Learning function
y: 0.95
eps: 0.5
decay_factor: 0.999

# Every how many episodes display the update in q-learning?
num_episodes_update: 100

# How many previous states of the environment to store?
stack_size: 3

# Num. of episodes to run simulate and learn
num_episodes: 5000

# Different states in which the environment might be.
state:
  portfolio_value:
    names:
      - EVEN
      - WINN
      - LOSE
  forecast:
    names:
      - STAL
      - GOUP
      - DOWN
  got_shares:
    names:
      - YESHAVE
      - NOTHAVE
  last_prediction:
    names:
      - PRED.UNKNW
      - PRED.CRECT
      - PRED.WRONG
#  stop_loss:
#    names:
#      - STOPLOSS
#      - NOSTPLOS

# Actions to be accomplished by the agent (Portfolio class)
action:
  - do_nothing
  - buy
  - sell

# Environment variables
environment:
  initial_budget: 2200.
  stop_loss: .05
  reward_do_nothing: -1
  reward_failed_buy: -1
  reward_success_buy: 0
  reward_failed_sell: -3
  reward_positive_sell: +10
  reward_negative_sell: -1
  reward_stoploss_donothing: -1
  reward_stoploss_buy: -100
  reward_stoploss_sell: +100

# Debug flag
debug: true