#
# Parameters to start a simulation with a trader
# @renero
#

# Data Path. Where is the data from which l#earning how to invest?
data_path: ../data/forecast100.csv

# Wanna save the model after training?
save_model: false
models_dir: ../output/

# Specify here if you want to load a pre-trained model
load_model: false
model_file: ../output/model3.json
weights_file: ../output/model3.h5

# Parameters for the Q-Learning function
y: 0.95
eps: 0.5
decay_factor: 0.999

# Every how many episodes display the update in q-learning?
num_episodes_update: 100

# How many previous states of the environment to store?
stack_size: 3

# Num. of episodes to run simulate and learn
num_episodes: 7500

# Different states in which the environment might be.
state:
  portfolio_value:
    names:
      - EVEN
      - WINN
      - LOSE
  forecast:
    names:
      - STAL
      - GOUP
      - DOWN
  got_shares:
    names:
      - YESHAVE
      - NOTHAVE
  last_prediction:
    names:
      - PRED_UNK
      - PRED_OOK
      - PRED_NOK
  stop_loss:
    names:
      - STOPLOSS
      - NOSTPLOS

# Actions to be accomplished by the agent (Portfolio class)
action:
  - do_nothing
  - buy
  - sell

# Environment variables
environment:
  initial_budget: 2200.
  stop_loss: .1
  reward_do_nothing: -1
  reward_failed_buy: -1
  reward_success_buy: 0
  reward_failed_sell: -3
  reward_positive_sell: +10
  reward_negative_sell: -1
  reward_stoploss_donothing: -10
  reward_stoploss_buy: -10
  reward_stoploss_sell: +10

# Debug flag
debug: true